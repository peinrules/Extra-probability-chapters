\documentclass[12pt,a4paper]{extarticle}

\usepackage{cmap}                   
\usepackage{mathtext}               
\usepackage[T1,T2A]{fontenc}        
\usepackage[utf8]{inputenc}         
\usepackage[english, russian]{babel} 

\usepackage[top=0.35in, bottom=0.5in, left=0.3in, right=0.3in]{geometry}
\usepackage{mathtools}              
\mathtoolsset{showmanualtags,mathic,centercolon}
\usepackage{amssymb}                
\usepackage{amsthm}                 
\usepackage{amstext}                
\usepackage{amsfonts}               
\usepackage{icomma}                 
\usepackage{enumitem}              
\usepackage{array}                  
\usepackage{multirow}
\usepackage{setspace}

\usepackage{algorithm}              
\usepackage{algorithmicx}           
\usepackage[noend]{algpseudocode}   
\usepackage{listings}              
\renewcommand{\algorithmicrequire}{\textbf{Input:}}              
\renewcommand{\algorithmicensure}{\textbf{Output:}}              
\floatname{algorithm}{Algorithm}                                 
\renewcommand{\algorithmiccomment}[1]{\hspace*{\fill}\{// #1\}}
\newcommand{\algname}[1]{\textsc{#1}}                          
\usepackage{physics}

\usepackage{euscript}               
\usepackage{mathrsfs}               

%% Графика
\usepackage{graphicx}       
\graphicspath{{images/}}            
\usepackage{tikz}  
\usetikzlibrary{patterns}                 
\usepackage{pgfplots}              
\usepackage{circuitikz}


\usepackage{indentfirst}                    
\usepackage{epigraph}                       
\usepackage{fancybox,fancyhdr}              
\usepackage[colorlinks=true,citecolor=blue]{hyperref} 
\usepackage{titlesec}                       
\usepackage[normalem]{ulem}                 
\usepackage[makeroom]{cancel}               
\usepackage{dsfont}

\usepackage{diagbox}
\usepackage{makecell}

\usepackage{csquotes}

\mathtoolsset{showonlyrefs=true}        
\renewcommand{\headrulewidth}{1.8pt}    
\renewcommand{\footrulewidth}{0.0pt}    

\usepackage{forest} 

\usetikzlibrary{arrows,calc}
\usetikzlibrary{quotes,angles}

\usetikzlibrary{positioning,intersections}

\usetikzlibrary{through}

\usepackage{enumitem}

\newenvironment{turing}[2]
{\begin{enumerate}[leftmargin=0pt,labelsep=0pt,align=left,parsep=0pt]
		\item[$#1={}$]``\ignorespaces#2
		%		\begin{enumerate}[
		nosep,
		align=left,
		labelwidth=1.5em,
		label=\bfseries\arabic{*}.,
		ref=\arabic{*}
		]}
	{\unskip''\end{enumerate}\end{enumerate}}

\newcommand{\bitem}{\item\hspace*{1em}\ignorespaces}

\usepackage{graphicx}

\newtheorem{definition}{Definition}[section]

\newtheorem*{task}{Task}
\newtheorem*{task0}{Task 0}
\newtheorem*{task1}{Task 1}
\newtheorem*{task2}{Task 2}
\newtheorem*{task3}{Task 3}
\newtheorem*{task4}{Task 4}
\newtheorem*{task5}{Task 5}
\newtheorem*{task6}{Task 6}
\newtheorem*{task7}{Task 7}
\newtheorem*{task8}{Task 8}
\newtheorem*{task9}{Task 9}
\newtheorem*{task10}{Task 10}
\newtheorem*{task11}{Task 11}
\newtheorem*{task12}{Task 12}

\newtheorem{theorem}{Theorem}
\newtheorem{proposal}{Proposal}
\newtheorem{notice}{Notice}
\newtheorem{statement}{Statement}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}
\newtheorem{problem}{Problem}
\newtheorem{claim}{Claim}


\newcommand{\note}{\underline{Note:} }
\newcommand{\fact}{\underline{\textbf{Fact}:} }
\newcommand{\example}{\underline{Example:} }


\renewcommand{\Re}{\mathrm{Re\:}}
\renewcommand{\Im}{\mathrm{Im\:}}
\newcommand{\Arg}{\mathrm{Arg\:}}
\renewcommand{\arg}{\mathrm{arg\:}}
\newcommand{\Mat}{\mathrm{Mat}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\aut}{\mathrm{aut}}
\newcommand{\isom}{\xrightarrow{\sim}} 
\newcommand{\leftisom}{\xleftarrow{\sim}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Ker}{\mathrm{Ker}\:}
\newcommand{\rk}{\mathrm{rk}\:}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\ort}{\mathrm{ort}}
\newcommand{\vol}{\mathrm{vol\:}}
\renewcommand{\mod}{\mathrm{\: mod\:}}
\DeclareMathOperator*\lowlim{\underline{lim}}
\DeclareMathOperator*\uplim{\overline{lim}}
\newcommand{\nd}{\mathbin{\&}}

\newcommand{\X}{\mathbb{X}}
%\newcommand{\D}{\mathbb{D}}
\newcommand{\Y}{\mathbb{Y}}
%\newcommand{\I}{\mathbb{I}}
\makeatletter
\DeclareRobustCommand{\I}{\operatorname{\mathds{I}}\@ifstar\@firstofone\@I}
\newcommand{\@I}[1]{\left\{#1\right\}}
\makeatother

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Qq}{\mathcal{Q}}
\newcommand{\N}{\mathbb{N}}
%\newcommand{\E}{\mathbb{E}} %
\makeatletter
\DeclareRobustCommand{\E}{\operatorname{\mathds{E}}\@ifstar\@firstofone\@E}
\newcommand{\@E}[1]{\left[#1\right]}
\makeatother

\makeatletter
\DeclareRobustCommand{\D}{\operatorname{\mathbb{D}}\@ifstar\@firstofone\@D}
\newcommand{\@D}[1]{\left[#1\right]}
\makeatother

\makeatletter
\DeclareRobustCommand{\Pr}{\operatorname{\mathds{P}}\@ifstar\@firstofone\@Pr}
\newcommand{\@Pr}[1]{\left[#1\right]}
\makeatother

\makeatletter
\DeclareRobustCommand{\Prnull}{\operatorname{\mathds{P}_0}\@ifstar\@firstofone\@Prnull}
\newcommand{\@Prnull}[1]{\left[#1\right]}
\makeatother

\makeatletter
\DeclareRobustCommand{\Prone}{\operatorname{\mathds{P}_1}\@ifstar\@firstofone\@Prone}
\newcommand{\@Prone}[1]{\left[#1\right]}
\makeatother

\makeatletter
\DeclareRobustCommand{\cov}{\operatorname{\mathrm{cov}}\@ifstar\@firstofone\@cov}
\newcommand{\@cov}[1]{\left(#1\right)}
\makeatother

\renewcommand{\S}{\mathbb{S}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}} 
\newcommand{\B}{\mathbb{B}}
\renewcommand{\C}{\mathbb{C}}
\renewcommand{\L}{\mathscr{L}}
%\renewcommand{\P}{\mathds{P}}


\newcommand{\orthog}{\mathop{\bot}}
\renewcommand*\d{\mathop{}\!\mathrm{d}}
\renewcommand*\dd{\mathop{}\!\partial}

%\renewcommand{\Pr}{\mathds{P}}
\newcommand{\pn}{\xrightarrow{\text{a. s.}}}
\newcommand{\pp}{\xrightarrow{\mathds{P}}}
\newcommand{\pd}{\xrightarrow{d}}
\newcommand{\ra}{\rightarrow}

\newcommand{\cond}{~|~}

\newcommand{\fe}{\varphi}
\newcommand{\e}{\varepsilon}
\newcommand{\ind}{\mathbin{\perp\!\!\!\perp}}
\newcommand{\Gauss}{\mathrm{Gauss}}
\newcommand{\hence}{\longrightarrow}
\newcommand{\bto}{\Longrightarrow}
\newcommand{\Bin}{\mathrm{Bin}}
\newcommand{\Bern}{\mathrm{Bern}}
\newcommand{\Geom}{\mathrm{Geom}}
\newcommand{\Uni}{\mathrm{U}}
\newcommand{\Exp}{\mathrm{Exp}}
\newcommand{\Ko}{\mathrm{Ko}}
\newcommand{\No}{\mathcal{N}}
\newcommand{\Pois}{\mathrm{Pois}}
\newcommand{\filtr}{\mathcal{F}}
\newcommand{\Filtr}{\mathbb{F}}

\newcommand{\pclass}{\mathsf{P}}
\newcommand{\npclass}{\mathsf{NP}}
\newcommand{\conpclass}{\mathsf{coNP}}

\newcommand{\rpclass}{\mathsf{RP}}
\newcommand{\corpclass}{\mathsf{coRP}}
\newcommand{\bppclass}{\mathsf{BPP}}
\newcommand{\ppclass}{\mathsf{PP}}
\newcommand{\zppclass}{\mathsf{ZPP}}

\newcommand{\conlclass}{\mathsf{coNL}}
\newcommand{\nlclass}{\mathsf{NL}}
\newcommand{\spaceclass}{\mathsf{SPACE}}
\newcommand{\pspaceclass}{\mathsf{PSPACE}}

     
\title{\Huge{ДЗ №2.3, Энтропия и последовательный анализ}}
\author{Павел Захаров}
\date{}
     
     
\begin{document}
	\maketitle

	
	\vspace{\baselineskip}

	
	
	\vspace{\baselineskip}
	\begin{task1}
		Докажите неравенство Фано: если $P(X \neq Y ) \leq \e$, то $H(X|Y) \leq \e \ln n + h(\e)$, где n -- число значений X.
	\end{task1}
	\begin{proof}[Решение]
		\
		Введем $I = \I{Y \neq X} \Rightarrow \e = \E{I} = \Pr{I = 1}$.
		
		Тогда:
		\[
			H(I, X \cond Y) = H(I, X, Y) - H(Y) = \{\text{применим св-во \#6 дважды}\}=
		\]
		\begin{itemize}
			\item[(1)]  $ = H(I \cond X, Y) + H(X \cond Y) + H(Y) - H(Y) = H(I \cond X, Y) + H(X \cond Y)$
			\
			\item[(2)] $ = H(X \cond I, Y) + H(I \cond Y) + H(Y) - H(Y) =  H(X \cond I, Y) + H(I \cond Y) $
		\end{itemize}
		Соответственно:
		\[
			H(I \cond X, Y) + H(X \cond Y) =  H(X \cond I, Y) + H(I \cond Y)
		\]
		$H(I \cond X, Y) = 0$, так как $I$ это функция от $X$ и $Y$. $H(I \cond Y) \leq H(I) = h(\e)$. Тогда:
		\[
			H(X \cond Y) \leq h(\e) + H(X \cond I, Y)
		\]
		Преобразуем последнее слагаемое. Для начала видоизменим определение условной энтропии (будем пользоваться определением условной энтропии в точке $H(X \cond Y = y)$):
		\[
			H(X\cond Y) =  - \sum_{i, j} \Pr{X = x_i, Y = y_j} \cdot \log_2 \Pr{X = x_i\cond Y = y_j} =
		\]
		\[
			= -\sum_j \Pr{Y = y_j} \sum_i \Pr{X = x_i \cond Y = y_j} \cdot \log_2 \Pr{X = x_i\cond Y = y_j}=
		\]
		\[
			=\{\text{по определению условной энтропии в точке}\}= \sum_j \Pr{Y = y_j} H(X \cond Y = y_j)
		\]
		Отсюда получим:
		\[
			H(X \cond I, Y) = \sum_i \Pr{Y = y_i, I = 0} \cdot  H(X \cond Y = y_i, I = 0) + \Pr{Y = y_i, I = 1} \cdot  H(X \cond Y = y_i, I = 1)
		\]
		Если $I = 0$, то $X = Y \Rightarrow H(X \cond Y, I = 0) = 0$. То есть:
		\[
			H(X \cond I, Y) = \sum_i \Pr{Y = y_i, I = 1} \cdot  H(X \cond Y = y_i, I = 1) = \Pr{I = 1} \cdot H(X \cond Y, I = 1)=
		\]
		\[
			= \e H(X \cond Y, I = 1) \leq \e H(x) \leq \e \ln n.
		\]
		Подставляя всё вместе, получаем:
		\[
			H(X \cond Y) \leq h(\e) +  \e \ln n.
		\]
		
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	
	

	\newpage
	

	\begin{task2}
		Докажите, что любых тех случайных величин X, Y, Z выполнено
		\[
			H(X, Y, Z) + H(X) \leq H(X, Y) + H(X, Z).
		\]
	\end{task2}
	\begin{proof}[Решение]
		\
		Распишем разность по определению (через обобщенную плотность):
		\[
			H(X, Y) + H(X, Z) - H(X, Y, Z) - H(X) 
			=
			-\sum_{a, b} p_{X Y}(a, b) \ln\left( p_{X Y}(a, b) \right) 
			-
			\sum_{a, c} p_{X Z}(a, c) \ln\left( p_{X Z}(a, c) \right) 
			+
		\]
		\[
			+\sum_{a, b, c} p_{X Y Z}(a, b, c) \ln\left( p_{X Y Z}(a, b, c) \right)
			+
			\sum_{a} p_{X}(a) \ln\left( p_{X}(a) \right) = \{\text{формула полной вероятности}\}=
		\]
		\[
			=-\sum_{a, b, c} p_{X Y Z}(a, b, c) \ln\left( { p_{X Y}(a, b)  p_{X Z}(a, c) \over  p_{X}(a)p_{X Y Z}(a, b, c)} \right)
			=
			-\E {\ln\left( { p_{X Y}(a, b)  p_{X Z}(a, c) \over  p_{X}(a)p_{X Y Z}(a, b, c)} \right)} \geq \{\text{нер-во Йенсена}\} \geq 
		\]
		\[
			\geq -\ln\left(\E{ p_{X Y}(a, b)  p_{X Z}(a, c) \over  p_{X}(a)p_{X Y Z}(a, b, c)}\right)
			=
			-\ln\left( \sum_{a, b, c} p_{X Y Z}(a, b, c)\cdot { p_{X Y}(a, b)  p_{X Z}(a, c) \over  p_{X}(a)p_{X Y Z}(a, b, c)} \right)=
		\]
		\[
			=-\ln\left( \sum_{a, b, c} { p_{X Y}(a, b)  p_{X Z}(a, c) \over  p_{X}(a)} \right) = -\ln\left( \sum_a {1\over p_X(a)} \sum_b p_{XY}(a, b) \sum_c p_{XZ}(a, c) \right)=
		\]
		\[
			= -\ln\left(\sum_a {1\over p_X(a)} \cdot p_X(a) \cdot p_X(a)\right)
			=
			-\ln\left(\sum_a p_X(a)\right) = -\ln(1) = 0.
		\]
		Неравенство доказано. Хотелось бы еще знать, где достигается равенство, но это мы рассмотрим в следущей задаче.
		
	\end{proof}
	
	
	\vspace{\baselineskip}
	
	
	
	
	
	
	
	
	
	
	
	
	\begin{task3}
		Пусть $X, Y$ -- случайные величины или векторы. Тогда их взаимной информацией называется
		\[
			I(X : Y) = H(X) + H(Y) - H(X, Y).
		\]
		Покажите, что если $(X_1 , X_2 , X_3)$ образуют марковскую цепь с конечным множеством значений, то
		\[
			I(X_1 : X_3) \leq I(X_1 : X_2).
		\]
	\end{task3}
	\begin{proof} [Решение]
		\
		Давайте введем понятие условной совместной информации:
		\[
			I(X : Y | Z) = I(X : Y, Z) - I(X : Z).
		\]
		Тогда:
		\[
			I(X_1 : X_2, X_3) = I(X_1 : X_3) + I(X_1 : X_2 \cond  X_3) = I(X_1 : X_2) + I(X_1 : X_3 \cond X_2).
		\]
		Запомним этот результат и отойдем в сторону. Назовём $X$ и $Z$ условно независимыми на $Y$, если $\Pr{X, Z \cond Y} = \Pr{X \cond Y} \cdot \Pr{Z \cond Y}$. Покажем, что если $X_1$, $X_2$, $X_3$ образуют марковскую цепь (в таком порядке), то $X_1$ и $X_3$ условно независимы на $X_2$:
		\[
			\Pr{X_1 = a_1, X_3 = a_3 \cond X_2 = a_2} = {\Pr{X_1 = a_1, X_3 = a_3, X_2 = a_2} \over \Pr{X_2 = a_2} } = 
		\]
		\[
			={\Pr{X_1 = a_1 \cond X_2 = a_2, X_3 = a_3} \cdot \Pr{X_2 = a_2, X_3 = a_3} \over \Pr{X_2 = a_2} } 
			=
			{\Pr{X_1 = a_1 \cond X_2 = a_2} \cdot \Pr{X_2 = a_2, X_3 = a_3} \over \Pr{X_2 = a_2} } = 
		\]
		\[
			= \Pr{X_1 = a_1 \cond X_2 = a_2} \cdot \Pr{X_3 = a_3 \cond X_2 = a_2}.
		\]
		Отлично. Теперь покажем, что если $X_1$ и $X_3$ условно независимы на $X_2$, то $I(X_1 : X_3 \cond X_2) = 0$:
		\[
			I(X_1 : X_3 \cond X_2) = H(X_1 \cond X_2) + H(X_3 \cond X_2) - H(X_1, X_3 \cond X_2) =
		\]
		\[
			= H(X_1, X_2) + H(X_3, X_2) - H(X_1, X_2, X_3) - H(X_2)
		\]
		Хотим показать, что это выражение равно нулб, когда $X_1$ и $X_3$ условно независимы на $X_2$. Распишем по определению (сразу свернем все суммы в одну, будем работать в терминах обобщенной плотности):
		\[
			H(X_1, X_2) + H(X_3, X_2) - H(X_1, X_2, X_3) - H(X_2) 
			=
			\sum_{a_1, a_2, a_3} p_{X_1 X_2 X_3}(a_1, a_2, a_3) \ln \left( {p_{X_1 X_2 X_3}(a_1, a_2, a_3) p_{X_2}(a_2) \over p_{X_1 X_2}(a_1, a_2) p_{X_2 X_3}(a_2, a_3)} \right) = 
		\]
		\[
			\sum_{a_1, a_2, a_3} p_{X_1 X_2 X_3}(a_1, a_2, a_3) \ln \left( {p_{X_1 X_2 X_3}(a_1, a_3 \cond a_2) p_{X_2}^2(a_2) \over p_{X_1 X_2}(a_1, a_2) p_{X_2 X_3}(a_2, a_3)} \right)
			= \{\text{условная независимость}\} =
		\]
		\[
			=\sum_{a_1, a_2, a_3} p_{X_1 X_2 X_3}(a_1, a_2, a_3) \ln \left( {p_{X_1 X_2 X_3}(a_1 \cond a_2)p_{X_1 X_2 X_3}(a_3 \cond a_2) p_{X_2}^2(a_2) \over p_{X_1 X_2}(a_1, a_2) p_{X_2 X_3}(a_2, a_3)} \right)=
		\]
		\[
			\sum_{a_1, a_2, a_3} p_{X_1 X_2 X_3}(a_1, a_2, a_3) \ln \left( {p_{X_1 X_1 X_2}(a_1, a_2) p_{X_1 X_2 X_3}(a_2, a_3) \over p_{X_1 X_2}(a_1, a_2) p_{X_2 X_3}(a_2, a_3)} \right) = \sum_{a_1, a_2, a_3} p_{X_1 X_2 X_3}(a_1, a_2, a_3) \ln \left(1\right) = 0
		\]
		Тогда из равенства
		\[
			I(X_1 : X_3) + I(X_1 : X_2 \cond  X_3) = I(X_1 : X_2) + I(X_1 : X_3 \cond X_2).
		\]
		Следует
		\[
			I(X_1 : X_3) + I(X_1 : X_2 \cond  X_3) = I(X_1 : X_2).
		\]
		Но $I(X_1 : X_2 \cond  X_3) = H(X_1, X_3) + H(X_2, X_3) - H(X_1, X_2, X_3) - H(X_3)$, что неотрицательно (см. задачу 2).
		
		Но в таком случае явно вытекает:
		\[
			I(X_1 : X_3) \leq I(X_1 : X_3) + I(X_1 : X_2 \cond  X_3) = I(X_1 : X_2).
		\]
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	\vspace{\baselineskip}
	
	
	\begin{task4}
		Пусть $\tau$ -- момент остановки наблюдения в критерии последовательного отношения правдоподобия, $\tau = \min\{n : A_0 < L_n < A_1\}$, где $0 < A_0 < 1 < A_1$ -- фиксированы. Докажите, что существуют такие $C > 0$ и $\delta \in (0, 1)$, что для каждого $n$ выполнено $\Pr{\tau \geq n} \leq C \cdot \delta^n$. Выведите отсюда, что $\E{\tau^k} < +\infty$ для всех натуральных k.
	\end{task4}
	\begin{proof}[Решение]
		\
		Событие <<момент остановки произошел после шага $n$>> включается в событие <<первые $n - 1$ шагов мы попадали в спорную область>>. То есть:
		\[
			\Pr{\tau \geq n} \leq \Pr{\bigcup_{k=1}^{n-1} A_0 < L_k < A_1} =
			\{\text{проверяем гипеотезы с плотностями $p_0$ и $p_1$}\} =
		\]
		\[
			 =
			 \Pr{\bigcup_{k=1}^{n-1} A_0 < \prod_{m=1}^k {p_1(x_m) \over p_0(x_m)} < A_1}
			 =
			 \Pr{\bigcup_{k=1}^{n-1} \ln A_0 < \sum_{m=1}^k \ln \left({p_1(x_m) \over p_0(x_m)}\right) < \ln A_1}=
		\]
		\[
			=\Pr{\bigcup_{k=1}^{n-1} \ln A_0 < \ln \left(L_{k-1}\right) + \ln \left({p_1(x_k) \over p_0(x_k)}\right) < \ln A_1}
			=
		\]
		\[
			=\Pr{\bigcup_{k=1}^{n-1} \ln A_0 - \ln \left(L_{k-1}\right) <  \ln \left({p_1(x_k) \over p_0(x_k)}\right) < \ln A_1 - \ln \left(L_{k-1}\right)} 
			\leq 
			\{A_0 < L_{k-1} < A_1\} \leq
		\]
		\[
			\leq
			\Pr{\bigcup_{k=1}^{n-1} \ln A_0 - \ln A_1 <  \ln \left({p_1(x_k) \over p_0(x_k)}\right) < \ln A_1 - \ln A_0} = \{x_1, \ldots, x_{n-1} \text{ независимы в совокупности}\} =
		\]
		\[
			=\prod_{k=1}^{n-1}\Pr{\ln A_0 - \ln A_1 <  \ln \left({p_1(x_k) \over p_0(x_k)}\right) < \ln A_1 - \ln A_0}.
		\]
		Внесем небольшую поправку: $L_0$ входит в объеденение честным образом, так как мы не можем взять ограничения на уже имеющееся правдоподобие на самом первом шаге. Но это событие зависит только от $x_0$, то есть тоже выносится по независимости. 
		
		Обозначим вероятность в произведении за $\delta$. Все множители (кроме нулевого) будут равны, так как $x_k$ одинакого распределены. Получается, что:
		\[
			\Pr{\tau \geq n} \leq \delta^{n-1} \cdot \Pr{A_0 < {p_1(x_0) \over p_0(x_0)} < A_1} = \{\text{обозначим правый множитель за $C'$}\} = \delta^{n-1} \cdot C' =
		\]
		\[
			= \delta^{n} \cdot C, \text{ где $C = C' / \delta$, положительная константа}. 
 		\]
 		
 		Покажем вторую часть:
 		\[
 			\E{\tau^k} = \sum_{m=1}^{+\infty} m^k\cdot\Pr{\tau = m} \leq \sum_{m=1}^{+\infty} m^k\cdot\Pr{\tau \leq m} \leq C \cdot \sum_{m=1}^{+\infty} m^k \delta^m \leq 
 		\]
 		\[
 			\leq  C \cdot \sum_{m=1}^{+\infty} (m+1)\cdot(m+2)\cdot \ldots \cdot (m+k) \delta^m = C \cdot \sum_{m=1}^{+\infty} (\delta^{m+k})^{(k)} = C \cdot \left(\sum_{m=1}^{+\infty} \delta^{m+k}\right)^{(k)} = 
 		\]
 		\[
 			= C \cdot \left({\delta^{k+1} \over 1 - \delta}\right)^{(k)} 
 			=
 			C \cdot \left(-{1 - \delta^{k+1} \over 1 - \delta } + {1 \over1 - \delta }\right)^{(k)} 
 			=
 			C \cdot \left(-(1 + x + \ldots + x^{k-1}) + {1 \over1 - \delta }\right)^{(k)}
 			=
 		\]
 		\[
 			= \left({1 \over1 - \delta }\right)^{(k)} = {(-1)^k \over (1-\delta)^{k+1}} < +\infty.
 		\]
 		
 		
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	\vspace{\baselineskip}
	
	
	\begin{task5}
		Рассмотрим задачу построения критерия последовательного отношения прав-
		доподобия для выборки из биномиального распределения $\Bin(1, p)$, $H_0 : p = p_0 < 1/2$, $H_1 : p = p_1$. Положим $q_i = 1 - p_i$. Предположим, что $p_1 = q_0$ и числа $A_0 , A_1$ подобраны так, что
		\[
			{\ln A_0 \over \ln(q_0 / p_0)} = -a, \quad	{\ln A_1 \over \ln(q_0 / p_0)} = b,
		\]
		где a и b -- положительные целые числа. Вычислите вероятности ошибок
		первого и второго рода для подобного критерия.
	\end{task5}
	\begin{proof}[Решение]
		\
		Выразим $A_0$ и $A_1$:
		\[
			A_0 = \left( {q_0 \over p_0} \right)^{-a}, \quad A_1 = \left( {q_0 \over p_0} \right)^{b}
		\]
		Выпишем отношение правдоподобия:
		\[
			L_n = \left({p_1 \over p_0}\right)^{\sum_i \I{x_i = 1}} \cdot \left({q_1 \over q_0}\right)^{n - \sum_i \I{x_i = 1}} = 
			\{q_0 = p_q\}
			=
			\left({q_0 \over p_0}\right)^{\sum_i \I{x_i = 1}} \cdot \left({p_0 \over q_0}\right)^{n - \sum_i \I{x_i = 1}}
		\]
		Обозначим $\tau := $ момент остановки. Посчитаем ошибку первого рода:
		\[
			\Prnull{L_{\tau} \geq A_1} 
			= 
			\Prnull{\left({q_0 \over p_0}\right)^{\sum_i \I{x_i = 1}} \cdot \left({p_0 \over q_0}\right)^{\tau - \sum_i \I{x_i = 1}} \geq \left( {q_0 \over p_0} \right)^{b}} =
		\]
		\[
			=\Prnull{\left({q_0 \over p_0}\right)^{2\sum_i \I{x_i = 1} - \tau} \geq \left( {q_0 \over p_0} \right)^{b}}
			=
			\Prnull{\left({2\sum_i \I{x_i = 1} - \tau}\right)\cdot\ln\left({q_0 \over p_0}\right) \geq b\cdot \ln\left( {q_0 \over p_0} \right)} = \left\{{q_0 \over p_0} > 1\right\}=
		\]
		\[
			=\Prnull{{2\sum_i \I{x_i = 1} - \tau} \geq b}.
		\]
		Если посмотреть на левую часть выражения, то увидим, что это просто случайное блуждание на прямой с вероятностью шага вправо $p_0$. А случайное блуждание с остановкой в момент выхода за заданные границы есть задача о разорении игрока, для которой мы знаем вероятности выигрыша и проигрыша. Тогда:
		\[
			\Prnull{{2\sum_i \I{x_i = 1} - \tau} \geq b} = \Prnull{S_{\tau} \geq b} = \Prnull{S_{\tau} =  b} = 1 - \Prnull{S_{\tau} =  -a} =
		\]
		\[
			=1 - {\left( {q_0 \over p_0} \right)^b - \left( {q_0 \over p_0} \right)^0 \over \left( {q_0 \over p_0} \right)^{b} - \left( {q_0 \over p_0} \right)^{-a}} 
			=
			{1 - \left( {q_0 \over p_0} \right)^{-a} \over \left( {q_0 \over p_0} \right)^{b} - \left( {q_0 \over p_0} \right)^{-a}}.
		\]
		Аналогично для ошибки второго рода:
		\[
			\Prone{L_{\tau} \leq A_0} 
			= 
			\Prone{\left({q_0 \over p_0}\right)^{\sum_i \I{x_i = 1}} \cdot \left({p_0 \over q_0}\right)^{\tau - \sum_i \I{x_i = 1}} \leq \left( {q_0 \over p_0} \right)^{-a}} 
			=
			\Prone{\left({q_0 \over p_0}\right)^{2\sum_i \I{x_i = 1} - \tau} \leq \left( {q_0 \over p_0} \right)^{-a}}=
		\]
		\[
			=
			\Prone{\left({2\sum_i \I{x_i = 1} - \tau}\right)\cdot\ln\left({q_0 \over p_0}\right) \leq -a\cdot \ln\left( {q_0 \over p_0} \right)} = \left\{{q_0 \over p_0} > 1\right\}
			=
			\Prone{{2\sum_i \I{x_i = 1} - \tau} \leq -a}.
		\]
		Воспользуемся аналогичными рассуждениями:
		\[
			\Prone{{2\sum_i \I{x_i = 1} - \tau} \leq -a} 
			=
			\Prone{S_{\tau} \leq -a} = \Prone{S_{\tau} = -a} 
			=
		\]
		\[
			=
			{\left( {q_1 \over p_1} \right)^b - \left( {q_1 \over p_1} \right)^0 \over \left( {q_1 \over p_1} \right)^{b} - \left( {q_1 \over p_1} \right)^{-a}} 
			=
			{\left( {p_0 \over q_0} \right)^b - 1 \over \left( {p_0 \over q_0} \right)^{b} - \left( {p_0 \over q_0} \right)^{-a}}.
		\]
	\end{proof}
	
	
\end{document}